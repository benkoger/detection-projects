{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7210a62-0eb9-4fe2-95cc-81bd369d79f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2498c9b0-6a4e-4712-bd17-9af01ce874e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "try:\n",
    "    import labelbox \n",
    "except ImportError:\n",
    "    print(\"Warning labelbox not installed.\")\n",
    "    \n",
    "from koger_detection.utils.video import extract_crops\n",
    "# from koger_detection.labelbox.annotations import\n",
    "\n",
    "# def extract_crops(video_names, video_folder_path, save_folder, num_extract, \n",
    "#                   crop_size, min_frame=0, max_frame=None, save_triplet=False, \n",
    "#                   triplet_spacing=30):\n",
    "#     \"\"\"Extract random crops from video clips.\n",
    "    \n",
    "#     Can extract frames a set time before and after each crop to\n",
    "#     make annotation easier so the annotator can use local movement.\n",
    "    \n",
    "#     video_names: list of names of video clips\n",
    "#     video_folder_path: full path to folder where videos are stored\n",
    "#     save_folder: full path to folder where crops should be saved\n",
    "#     num_extract: how many random focal frames to extract from each\n",
    "#         video clip\n",
    "#     crop_size: length of square crop in pixels\n",
    "#     min_frame: min frame number in video frames should be chosen from \n",
    "#     max_frame: max frame number in video frames should be chosen from\n",
    "#     save_triplet: if True, save frames a fixed number of frames before\n",
    "#         and after focal frame to aid in annoation effort\n",
    "#     triplet_spacing: how many frames before and after focal frame triplet\n",
    "#         frames should be. (Only relevant if triplet spacing is True)\n",
    "    \n",
    "#     \"\"\"\n",
    "#     for video_name in video_names:\n",
    "#         video_file = os.path.join(video_folder_path, video_name)\n",
    "#         video_name = os.path.splitext(video_name)[0] # remove extension\n",
    "\n",
    "#         cap = cv2.VideoCapture(video_file)\n",
    "#         width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#         height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#         if max_frame is None:\n",
    "#             max_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) + 1\n",
    "#         if save_triplet:\n",
    "#             # Only choose frames for annotation that have space before and after\n",
    "#             # for all frames in triplet\n",
    "#             max_frame -= triplet_spacing - 1\n",
    "#             min_frame += triplet_spacing\n",
    "#         # Randomly choose the specified number of frames to extract from the given range\n",
    "#         frame_nums_to_save = np.random.randint(min_frame, max_frame, num_extract)\n",
    "#         for frame_num in frame_nums_to_save:\n",
    "#             frame_file = os.path.join(save_folder, f\"{video_name}_frame_{frame_num}\")\n",
    "#             if crop_size:\n",
    "#                 # If gaussian is True, then random crops sampled from gaussian \n",
    "#                 # centered at center of frame with 1 std equal to half height/width \n",
    "#                 # of the frame\n",
    "#                 top_left = random_top_left([height, width], crop_size, gaussian=False)\n",
    "#                 if top_left is False:\n",
    "#                     print(f\"skipping {frame_file}\")\n",
    "#                     print(f\"No valid crop found. Check frame size and crop size.\")\n",
    "#                     print(f\"Frame size h:{height}, w:{width}, crop_size: {crop_size}.\")\n",
    "#                     continue\n",
    "#                 # Add where crop comes from to file name so we can find it in the \n",
    "#                 # original image later if we want to\n",
    "#                 frame_file += f\"_top_{top_left[0]}_left_{top_left[1]}\"\n",
    "#             # Naming convention here is to append an 'f' if the focal frame that will\n",
    "#             # be annotated and a 'a' or 'b' if the first or last frame in a triplet\n",
    "#             save_frame(cap, frame_num, frame_file+\"_f.jpg\", crop_size, top_left)\n",
    "#             if save_triplet:\n",
    "#                 next_frame_num = frame_num + triplet_spacing\n",
    "#                 frame_file = os.path.join(save_folder, f\"{video_name}_frame_{frame_num}\")\n",
    "#                 if crop_size:\n",
    "#                     frame_file += f\"_top_{top_left[0]}_left_{top_left[1]}\"\n",
    "#                 save_frame(cap, next_frame_num, frame_file+\"_a.jpg\", \n",
    "#                            crop_size, top_left\n",
    "#                           )\n",
    "#                 prev_frame_num = frame_num - triplet_spacing \n",
    "#                 frame_file = os.path.join(save_folder, f\"{video_name}_frame_{frame_num}\")\n",
    "#                 if crop_size:\n",
    "#                     frame_file += f\"_top_{top_left[0]}_left_{top_left[1]}\"\n",
    "#                 save_frame(cap, prev_frame_num, frame_file+\"_b.jpg\",\n",
    "#                            crop_size, top_left\n",
    "#                           )\n",
    "#         cap.release()\n",
    "    \n",
    "\n",
    "# def random_top_left(im_shape, crop_size, gaussian=False):\n",
    "#     \"\"\" Get a random top left coordinate for a crop of size (crop_size * crop_size).\n",
    "    \n",
    "#     Args:\n",
    "#         im_shape: (h, w, ...)\n",
    "#         crop_size: size of ultimate crop\n",
    "#         gaussian: If True, then pull coordinates from gaussian with mean\n",
    "#             at the center of possible range of top left values and 1 standard \n",
    "#             deviation to the min and max top left values\n",
    "    \n",
    "#     Returns [top, left] \n",
    "#         or False if no valid top_left value based on image and crop size\n",
    "#     \"\"\"\n",
    "    \n",
    "#     height, width = im_shape[:2]\n",
    "#     if gaussian:\n",
    "#         mean_top = (width-crop_size) / 2\n",
    "#         mean_left = (width-crop_size) / 2\n",
    "#         top = -1\n",
    "#         left = -1\n",
    "#         while ((top >= (height-crop_size)) or (top < 0)):\n",
    "#             top = int(np.random.normal(mean_top, mean_top))\n",
    "#         while ((left >= (width-crop_size)) or (left < 0)):\n",
    "#             left = int(np.random.normal(mean_left, mean_left))\n",
    "#     else:\n",
    "#         if height - crop_size < 0:\n",
    "#             return False\n",
    "#         top = np.random.randint(0, height-crop_size)\n",
    "\n",
    "#         if width - crop_size < 0:\n",
    "#             return False\n",
    "#         left = np.random.randint(0, width-crop_size)\n",
    "\n",
    "#     top_left = [top, left]\n",
    "#     return top_left\n",
    "\n",
    "\n",
    "# def save_frame(cap, frame_num, outfile, crop_size=None, top_left=None):\n",
    "#     \"\"\" Save frame from cv2 VideoCapture\n",
    "    \n",
    "#     Args: \n",
    "#         cap: cv2.VideoCapture object\n",
    "#         frame_num: the frame number to save\n",
    "#         outfile: where to save frame\n",
    "#         crop_size: pixels, size of crop (square). If None, no crop.\n",
    "#         top_left: (i, j) coordinate of top left corner of crop (if not None)\n",
    "#             if None and crop_size is not None, then choose random values\n",
    "            \n",
    "#     Return crop_top_left\n",
    "        \n",
    "#     \"\"\"\n",
    "#     cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "#     ret, frame = cap.read()\n",
    "#     if frame is not None:\n",
    "#         if crop_size:\n",
    "#             if not top_left:\n",
    "#                 raise ValueError(f\"If cropping, must provide top_left: {top_left}\")\n",
    "#             top, left = top_left\n",
    "#             frame = frame[top:top+crop_size, left:left+crop_size]\n",
    "\n",
    "#         os.makedirs(os.path.dirname(outfile), exist_ok=True)\n",
    "#         cv2.imwrite(outfile, frame)\n",
    "#     else:\n",
    "#         print(f\"Frame doesn't exist {outfile}.\")\n",
    "        \n",
    "\n",
    "# def create_storage_dataset(labelbox_client, image_files, dataset_name):\n",
    "#     \"\"\"First create dataset with images including overlay images\n",
    "#     so that they are given an online adress by labelbox. Nessisary\n",
    "#     step to eventually have overlay dataset for focal frames.\n",
    "    \n",
    "#     Args:\n",
    "#         labelbox_client: labelbox Client object\n",
    "#         image_files: list of files to upload to labelbox dataset\n",
    "#         dataset_name: name of the final overlay dataset to be annotated\n",
    "#             ('-storage' will be appended)\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # This dataset is just for uploading all images to the cloud\n",
    "#     # In a second dataset some of these images will become overlay images\n",
    "#     # So the user can use animal movement to help detect crypric individuals\n",
    "#     storage_dataset = labelbox_client.create_dataset(name=f\"{dataset_name}-storage\")\n",
    "\n",
    "#     # Create data payload\n",
    "#     # External ID is recommended to identify your data\n",
    "#     my_data_rows = []\n",
    "#     for image_file in image_files:\n",
    "#         my_data_rows.append({\"row_data\": image_file,\n",
    "#                              \"external_id\": os.path.basename(image_file)\n",
    "#                             }\n",
    "#                            )\n",
    "#     # Bulk add data rows to the dataset\n",
    "#     task = storage_dataset.create_data_rows(my_data_rows)\n",
    "#     task.wait_till_done()\n",
    "#     while task.status != \"COMPLETE\":\n",
    "#         print(f\"Storage dataset upload status: {task.status}\")\n",
    "#         time.sleep(3)\n",
    "#     return task.status == \"COMPLETE\"\n",
    "        \n",
    "        \n",
    "# def add_crops_to_labelbox(labelbox_client, focal_images, dataset_name):\n",
    "#     \"\"\" Create labelbox dataset with overlay images around focal image.\n",
    "    \n",
    "#     Args: \n",
    "#         labelbox_client: labelbox Client object\n",
    "#         focal_images: list of focal image full paths\n",
    "#             (These are the files that are going to actually be \n",
    "#             annotated (marked by _f))\n",
    "#         dataset_name: name of the dataset \n",
    "            \n",
    "#         \"\"\"\n",
    "    \n",
    "#     focal_names = [os.path.basename(f) for f in focal_images]\n",
    "    \n",
    "#     dataset = labelbox_client.create_dataset(name=dataset_name)\n",
    "    \n",
    "#     storage_ds = labelbox_client.get_datasets(\n",
    "#         where=labelbox.Dataset.name == f\"{dataset_name}-storage\").get_one()\n",
    "\n",
    "#     my_data_rows = []\n",
    "\n",
    "#     for focal_name in focal_names:\n",
    "#         prev_name = focal_name.split(\"_f.jpg\")[0] + \"_a.jpg\"\n",
    "#         next_name = focal_name.split(\"_f.jpg\")[0] + \"_b.jpg\"\n",
    "#         data_row = storage_ds.data_row_for_external_id(focal_name)\n",
    "#         prev_row = storage_ds.data_row_for_external_id(prev_name)\n",
    "#         next_row = storage_ds.data_row_for_external_id(next_name)\n",
    "\n",
    "#         my_data_rows.append({\"row_data\": data_row.row_data,\n",
    "#                              \"external_id\": data_row.external_id,\n",
    "#                              \"attachments\": [\n",
    "#                                  {\n",
    "#                                      \"type\": \"IMAGE_OVERLAY\",\n",
    "#                                      \"value\": prev_row.row_data\n",
    "#                                  },\n",
    "#                                  {\n",
    "#                                      \"type\": \"IMAGE_OVERLAY\",\n",
    "#                                      \"value\": next_row.row_data\n",
    "#                                  }\n",
    "#                              ]\n",
    "#                             }\n",
    "#                            )\n",
    "\n",
    "#     # Bulk add data rows to the dataset\n",
    "#     task = dataset.create_data_rows(my_data_rows)\n",
    "\n",
    "#     task.wait_till_done()\n",
    "#     while task.status != \"COMPLETE\":\n",
    "#         print(f\"Storage dataset upload status: {task.status}\")\n",
    "#         time.sleep(3)\n",
    "#     return f\"successful upload: {task.status == 'COMPLETE'}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89ade77-04af-4b5c-b0d9-141838ab36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # This file records which raw video files should be used for \n",
    "# # training, validation, and testing\n",
    "# # Format of .json is:\n",
    "# # {\"train\": [\"file1.mp4\", \"file2.mp4\"], \n",
    "# #  \"val\": [\"file3.mp4\", \"file4.mp4\"],\n",
    "# #  \"test\": [\"file5.mp4\", \"file6.mp4\"]\n",
    "# # }\n",
    "\n",
    "# # can instead just manually create a list of video names\n",
    "# # and pass that to the variable 'video_names' below\n",
    "# json_file = \"/home/koger/Dropbox/UWWRF/detection/high-altitude/high-altitude-overhead/detection/model-training/video_train_val_test_split.json\"\n",
    "# with open(json_file) as f:\n",
    "#     video_splits = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0001dd84-26a1-460a-8567-20e82e4f2610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder where videos are saved\n",
    "video_folder_path = \"/mnt/e/porcupine-island-2023/drone-flights\"\n",
    "\n",
    "# Which type of videos to extract from based on naming in our saved .json file\n",
    "# this could be \"train\", \"validate\", or \"test\"\n",
    "project_name = \"confluence_2023\"\n",
    "data_type = \"train\"\n",
    "annotation_round = 1\n",
    "\n",
    "# Path to main folder within which images will be saved\n",
    "annotations_folder = f\"/mnt/c/Users/benko/Dropbox/UWWRF/detection/{project_name}/annotations/extracted_frames\"\n",
    "os.makedirs(annotations_folder, exist_ok=True)\n",
    "\n",
    "dataset_name = f\"{project_name}-{data_type}_{annotation_round}\"\n",
    "\n",
    "# list of video names to use\n",
    "video_names = [\"confluence_big_2023_08_08_koger_04_08_DJI_20230808194259_0679_D.MP4\"] # video_splits[data_type]\n",
    "\n",
    "save_folder = os.path.join(annotations_folder, dataset_name)\n",
    "# setting min and max frames can be used if part of video will go in the training set\n",
    "# and part of the video will go in the validation set\n",
    "min_frame = 0 # begining of range frames could be extracted from\n",
    "max_frame = None # end of range (exclusive) frames could be extracted from (\n",
    "                 # set to \"None\" if range should extend through last frame)\n",
    "num_extract = 10 # number of frames to extract and save\n",
    "save_triplet = False # If True, for each frame should save a frame a little before \n",
    "                    # and a little after focal frame (Can be helpful when \n",
    "                    # movement helps find cryptic individuals)\n",
    "triplet_spacing = 20 # How many frames in future and past to space outer \n",
    "                     # triplet frames around focal frame (ignored if \n",
    "                    # save_triplet is False)\n",
    "crop_size = None # Either none for whole image or size in pixels (square crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a357a825-13cf-48a0-8798-305017abbd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_crops(video_names, video_folder_path, save_folder, \n",
    "              num_extract, crop_size, min_frame=min_frame, max_frame=max_frame,\n",
    "              save_triplet=save_triplet, triplet_spacing=triplet_spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69266fe2-9c4f-4b1b-a1b3-2ea0b3b621ce",
   "metadata": {},
   "source": [
    "### Upload frames to labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6bbcfa3-e64d-4a17-8ece-dc20a57ce874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from labelbox import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b7adb8b-ca71-4165-b3f9-020bdbe8586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = Client(api_key=os.environ.get('LABELBOX_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc99bf0-00eb-4728-843a-943e53b5f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_folder = \"/home/koger/Dropbox/UWWRF/detection/high-altitude/annotations/extracted_frames/crops/salmon-high-alt-train-3_1\"\n",
    "crop_files = sorted(glob.glob(os.path.join(save_folder, \"*.jpg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f3b06cd-dfac-4fa2-8a41-b9c376e3d53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uploads focal frames and \n",
    "create_storage_dataset(client, crop_files, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "072934ab-d3c5-4249-9e01-8e0a17bc721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_images = sorted(glob.glob(os.path.join(save_folder, \"*_f.jpg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4f09fcb-43a1-4b2e-87b5-8a110489310d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'successful upload: True'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_crops_to_labelbox(client, focal_images, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7bc6ae4-fca8-4c44-9301-14e926374b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/koger/Dropbox/UWWRF/detection/confluence_2023/annotations/extracted_frames'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2cd5b3b-a9b0-41d2-8da5-83d3f9924cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73994912-6050-49d0-9961-f0911230edfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "168b9a80-ce53-43cb-9a3b-a57e53ab53f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee6b994-8f8e-44ad-929c-cf05c1a1a1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d33eb4e8-2fd3-48f8-a0c4-9bac85b71316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5451c4a-21b8-4fe2-b5fd-e454e0364fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a98c69-bfe7-4205-937e-ddfedc7acd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd80bd-aabf-4807-bae9-821025c20be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da71be7-6fa1-4e7e-95a6-76ae488b0c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978622f-806a-4431-8921-2edd57b2de57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26460f0-8673-464c-95d0-f418aa232649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
